以下の内容で回答します。

⸻

1. 前提
	•	カメラはWindows側に接続済み
	•	プログラム実行はWSL2のUbuntu内のDockerコンテナ上
	•	Pythonで5秒間の映像を記録し、aviファイルとして保存

⸻

2. 注意点・追加設定

A. カメラの利用に関する注意
	•	WSL2やDockerコンテナではWindowsデバイス直アクセス不可が基本
	•	つまり、Windowsに物理接続されたカメラを、直接WSL2やその上のDockerから使うのはかなり制限ありです

解決パターン
	•	一番現実的な方法
	1.	Windows側でカメラをIPカメラ化して配信（例：OBSの仮想カメラ、MJPEG streamer、IP Webcamなど）
	2.	WSL2やDocker側からはネットワーク越しにストリームを取得（RTSP/HTTP/MJPEG等）

⸻

3. サンプル（IPカメラ配信の場合）

まずWindows側でIPカメラ配信設定をしてください。
例えば、IP Webcam（スマホの場合）や、OBSの「仮想カメラ＋配信」など。

Pythonサンプルコード（OpenCVで5秒録画）

import cv2
import time

# ここにIPカメラのURLをセット
# 例: "http://192.168.1.10:8080/video"
CAMERA_URL = "http://<windows_ip>:<port>/video"

# 動画保存設定
output_file = "output.avi"
fps = 20.0    # フレームレート
record_sec = 5  # 録画秒数

# ストリームオープン
cap = cv2.VideoCapture(CAMERA_URL)
if not cap.isOpened():
    print("カメラに接続できません")
    exit()

# 映像サイズ取得
width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

# 動画保存用のWriter
fourcc = cv2.VideoWriter_fourcc(*'XVID')
out = cv2.VideoWriter(output_file, fourcc, fps, (width, height))

start = time.time()
while (time.time() - start) < record_sec:
    ret, frame = cap.read()
    if not ret:
        break
    out.write(frame)

cap.release()
out.release()
print(f"{output_file} に保存しました")


⸻

4. もし「USBカメラを直接使いたい」場合

1. WSL2のUbuntuで
	•	/dev/video* が見えていれば cv2.VideoCapture(0) などでアクセス可能
	•	ただし通常WSL2では直接は見えない
	•	Windows側で「カメラを共有」する方法があるが、現状公式にはサポートされていない（将来のWindows/WSL2更新で改善される可能性あり）

2. Dockerコンテナで
	•	--device=/dev/video0 などでデバイスをマウントして起動する
	•	例:

docker run --rm -it --device=/dev/video0:/dev/video0 your_image


	•	ただし、前述の通りWSL2でUSBパススルーは基本できない

⸻

5. まとめ

おすすめ構成
	•	Windows側でカメラをIPカメラ化（ローカルネット配信）
	•	WSL2/Dockerからはネット越しに取得し録画

⸻

6. 参考：必要なパッケージ

Dockerfileで

RUN apt-get update && apt-get install -y python3-opencv ffmpeg

または

pip install opencv-python


⸻

ご希望の形や環境詳細（例：USBカメラ直結利用必須 or IPカメラ化可能か）などあれば教えてください。
どちらのルートでも細かく手順を案内できます！



はい、Windowsに接続した2台のカメラ映像をPythonに送り、Python側で合成することは可能です。

実現方法は大きく分けて2つあります。

⸻

1. Windowsで直接Pythonを使う場合（最も簡単・確実）

A. Python（OpenCV）で2台のカメラを同時に取得し合成する方法

import cv2
import numpy as np

# 0番目と1番目のカメラをオープン
cap1 = cv2.VideoCapture(0)
cap2 = cv2.VideoCapture(1)

if not cap1.isOpened() or not cap2.isOpened():
    print("カメラが認識できません")
    exit()

while True:
    ret1, frame1 = cap1.read()
    ret2, frame2 = cap2.read()
    if not ret1 or not ret2:
        break

    # サイズ揃える（必要に応じてリサイズ）
    h, w = frame1.shape[:2]
    frame2 = cv2.resize(frame2, (w, h))

    # 横方向に合成（左右連結）例
    combined = np.hstack((frame1, frame2))

    cv2.imshow('Combined Camera', combined)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap1.release()
cap2.release()
cv2.destroyAllWindows()

この方法のポイント：
	•	Windows上のPythonスクリプトで2台のUSBカメラから同時に映像を取得し、numpy.hstack などで合成
	•	映像の保存や配信も同時にできます（cv2.VideoWriterで録画、FlaskなどでHTTP配信）

⸻

2. Windows → WSL/Docker で分けて運用したい場合

A. Windowsでカメラ映像を配信（Webサーバ or 仮想カメラ）して、WSLから受け取る

ステップ
	1.	Windowsで各カメラごとにPython HTTP配信サーバを立てる（前述Flaskサンプルを2つポートを変えて起動）
	2.	WSL/Docker側でそれぞれのURLからストリーム取得、合成処理を行う

Windows側カメラ配信サンプル（2台分）

例：
	•	win_camera_stream_0.py（カメラ0→8080ポートで配信）
	•	win_camera_stream_1.py（カメラ1→8081ポートで配信）

カメラ番号だけ変更して、それぞれのPythonサーバを同時に起動。

# win_camera_stream_0.py
import cv2
from flask import Flask, Response

app = Flask(__name__)

def gen():
    cap = cv2.VideoCapture(0)
    while True:
        ret, frame = cap.read()
        if not ret:
            continue
        _, jpeg = cv2.imencode('.jpg', frame)
        yield (b'--frame\r\nContent-Type: image/jpeg\r\n\r\n' + jpeg.tobytes() + b'\r\n')

@app.route('/video')
def video_feed():
    return Response(gen(), mimetype='multipart/x-mixed-replace; boundary=frame')

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080, threaded=True)

※カメラ1用は cv2.VideoCapture(1) とポート番号を変えて同様に。

WSL側での合成サンプル

import cv2
import numpy as np

URL1 = 'http://<windows_ip>:8080/video'
URL2 = 'http://<windows_ip>:8081/video'

cap1 = cv2.VideoCapture(URL1)
cap2 = cv2.VideoCapture(URL2)

while True:
    ret1, frame1 = cap1.read()
    ret2, frame2 = cap2.read()
    if not ret1 or not ret2:
        continue
    # 必要に応じてリサイズ
    h, w = frame1.shape[:2]
    frame2 = cv2.resize(frame2, (w, h))
    combined = np.hstack((frame1, frame2))
    cv2.imshow('Combined', combined)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
cap1.release()
cap2.release()
cv2.destroyAllWindows()


⸻

3. OBS利用パターンも可能
	•	OBSで2台のカメラを取り込み「仮想カメラ」として配信
	•	Pythonから仮想カメラを cv2.VideoCapture で受け取ることもできる（ただし合成はOBS内で）

⸻

4. 注意点
	•	Windowsで2台のUSBカメラを同時利用できるかは、カメラ機種やUSB帯域で制限あり（稀に片方しか認識しない場合もある）
	•	WSL2やDockerだけでUSBカメラを直接操作するのは困難（基本的にWindowsでキャプチャし、ネットワーク越しに映像転送が現実的）

⸻

まとめ
	•	一番確実・シンプルなのは「Windows上でPythonで2台のカメラ取得→合成」
	•	WSLやDockerで合成したい場合は「WindowsでHTTP配信→WSLで取得・合成」も可能
	•	OBSも使えるが、OBS内合成→仮想カメラ出力になる

⸻

必要な方式・用途（録画、リアルタイム処理、ネット配信…など）によって最適案を具体化できます。

どの方法でやりたいか、もう少し希望を教えてもらえれば、コードや設定まで詰めてご案内します！


----------

import cv2
import time

device = "/dev/video0"
output_file = "output.avi"
duration = 5  # 秒

cap = cv2.VideoCapture(device)

# 失敗時
if not cap.isOpened():
    print("カメラが開けません")
    exit(1)

# カメラのフレームサイズ、FPSを取得
fps = cap.get(cv2.CAP_PROP_FPS)
if fps == 0:  # 機種依存で0になることがあるので、デフォルト30に
    fps = 30
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
size = (width, height)

print(f"録画サイズ: {size}, FPS: {fps}")

# 出力用VideoWriter
fourcc = cv2.VideoWriter_fourcc(*'XVID')
out = cv2.VideoWriter(output_file, fourcc, fps, size)

start = time.time()
while True:
    ret, frame = cap.read()
    if not ret:
        print("フレーム取得失敗")
        break
    out.write(frame)
    if time.time() - start > duration:
        break

cap.release()
out.release()
print(f"録画完了: {output_file}")



---


import cv2
import os
import time
import subprocess

def print_section(title):
    print("\n" + "="*30)
    print(title)
    print("="*30)

def show_video_devices():
    print_section("デバイス一覧 (/dev/video*)")
    os.system("ls -l /dev/video* 2>/dev/null")

    print_section("v4l2-ctl --list-devices")
    try:
        subprocess.run(["v4l2-ctl", "--list-devices"], check=False)
    except Exception as e:
        print("v4l2-ctlが実行できません:", e)

def show_user_info():
    print_section("ユーザ・グループ情報")
    os.system("id")

def try_capture(dev):
    print_section(f"{dev} カメラテスト")
    cap = cv2.VideoCapture(dev)
    if not cap.isOpened():
        print(f"{dev}: cap.isOpened() = False（カメラが開けません）")
        return False, None, None, None

    # 基本情報取得
    fps = cap.get(cv2.CAP_PROP_FPS)
    if not fps or fps < 1:
        fps = 30  # デフォルト
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    print(f"{dev}: 幅={width}, 高さ={height}, FPS={fps}")

    # 解像度を明示セット
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

    # 1フレームだけ読んでみる
    ret, frame = cap.read()
    print(f"{dev}: 1フレーム取得結果: {ret}, shape: {frame.shape if ret else None}")

    cap.release()
    return ret, fps, (width, height), frame

def record_video(dev, output_file, duration_sec=5):
    print_section(f"{dev} から録画開始")
    cap = cv2.VideoCapture(dev)
    if not cap.isOpened():
        print(f"{dev}: cap.isOpened() = False（録画できません）")
        return False

    fps = cap.get(cv2.CAP_PROP_FPS)
    if not fps or fps < 1:
        fps = 30
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    size = (width, height)
    print(f"録画: 幅={width}, 高さ={height}, FPS={fps}")

    fourcc = cv2.VideoWriter_fourcc(*'XVID')
    out = cv2.VideoWriter(output_file, fourcc, fps, size)

    start = time.time()
    frames = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            print("フレーム取得失敗（録画中）")
            break
        out.write(frame)
        frames += 1
        if time.time() - start > duration_sec:
            break

    cap.release()
    out.release()
    print(f"録画完了: {output_file}, 総フレーム数: {frames}")
    return True

if __name__ == "__main__":
    show_user_info()
    show_video_devices()

    dev = "/dev/video0"
    ret, fps, size, frame = try_capture(dev)
    if not ret:
        print(f"ERROR: {dev} からフレーム取得できません。他のデバイスも試してください。")
    else:
        print(f"{dev} からフレーム取得に成功。録画を試みます。")
        ok = record_video(dev, "output.avi", duration_sec=5)
        if ok:
            print("録画処理成功。output.avi を確認してください。")
        else:
            print("録画処理に失敗しました。")

---

import cv2
import time

# Windows側OBS-RTSPServerのIPとポートに合わせてください
RTSP_URL = "rtsp://<WindowsのIPアドレス>:8554/live"
OUTPUT_FILE = "output.avi"
RECORD_SECONDS = 5

print(f"RTSPから受信開始: {RTSP_URL}")
cap = cv2.VideoCapture(RTSP_URL)

if not cap.isOpened():
    print("RTSPストリームを開けません")
    exit(1)

fps = cap.get(cv2.CAP_PROP_FPS)
if fps == 0 or fps is None:
    fps = 30  # デフォルト
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
size = (width, height)
print(f"解像度: {size}, FPS: {fps}")

fourcc = cv2.VideoWriter_fourcc(*'XVID')
out = cv2.VideoWriter(OUTPUT_FILE, fourcc, fps, size)

start = time.time()
frames = 0

while True:
    ret, frame = cap.read()
    if not ret:
        print("フレーム取得失敗")
        break
    out.write(frame)
    frames += 1
    if time.time() - start > RECORD_SECONDS:
        break

cap.release()
out.release()
print(f"録画完了: {OUTPUT_FILE}, 総フレーム数: {frames}")




netsh advfirewall firewall add rule name="Allow ICMPv4-In" protocol=icmpv4:8,any dir=in action=allow
netsh advfirewall firewall add rule name="Allow RTSP 8554" dir=in action=allow protocol=TCP localport=8554

netsh advfirewall firewall add rule name="Allow RTSP 8554" dir=in action=allow protocol=TCP localport=8554


