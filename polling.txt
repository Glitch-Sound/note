FastAPI、PostgreSQL、Python実行環境がそれぞれDockerコンテナで構成されているとのこと、ポーリングをやめて非同期・イベント駆動で処理を行いたいというニーズに対して、以下の選択肢をおすすめします。

⸻

✅ オススメの構成（ポーリング廃止）

🧩 1. Redis + Celery
	•	用途: 非同期タスクキュー
	•	概要:
	•	FastAPIからRedisにジョブを投げる
	•	Python実行環境はCeleryワーカーとして待機
	•	Redisがメッセージを仲介するため、ポーリングは不要
	•	メリット:
	•	軽量、導入が容易
	•	FastAPIとの相性も良い（celery[redis]）
	•	関連パッケージ:
	•	celery
	•	redis
	•	flower（Web UIでジョブ管理）

# FastAPI 側
from celery import Celery

celery_app = Celery('tasks', broker='redis://redis:6379/0')

@celery_app.task
def process_job(data):
    # ここに処理内容
    pass


⸻

🧩 2. RabbitMQ + Celery
	•	用途: Redisより信頼性が必要な場合
	•	概要:
	•	Redisと同じCeleryベースだが、ブローカーにRabbitMQを使う
	•	複数コンシューマや複雑なルーティングが可能
	•	おすすめ対象: 高信頼が必要な業務処理に向く

⸻

🧩 3. PostgreSQLのNOTIFY/LISTEN機能
	•	用途: PostgreSQLだけで簡易Pub/Subを実現
	•	概要:
	•	FastAPIがNOTIFY発行
	•	PythonがLISTENして待機（asyncpgなどで実装）
	•	メリット:
	•	追加ミドルウェア不要
	•	軽い構成にしたい場合に最適
	•	デメリット:
	•	複雑なキュー処理やリトライには向かない

# Python側（asyncpg使用）
conn = await asyncpg.connect(...)
await conn.add_listener('job_channel', callback)


⸻

🔧 どれを選ぶべき？

要件	推奨構成
軽量・簡単に導入したい	Redis + Celery
高信頼、スケーラブル	RabbitMQ + Celery
追加ミドルウェアを増やしたくない	PostgreSQL NOTIFY/LISTEN


⸻

✍️ 補足：Docker構成イメージ

services:
  fastapi:
    build: ./fastapi
    depends_on: [redis]
  worker:
    build: ./worker
    command: celery -A tasks worker --loglevel=info
    depends_on: [redis]
  redis:
    image: redis:7


⸻

了解です！
以下に、FastAPI（リクエスト受付側）とPython実行環境（ワーカー）をRedis + Celeryで連携させる最小限の構成サンプルを示します。

⸻

🧩 前提構成
	•	FastAPI：ユーザーのリクエストを受け取ってタスクを投入
	•	Redis：Celeryのブローカーとして使用（redis://redis:6379/0）
	•	Celery Worker（Python）：Redisに入ったタスクを非同期で実行

⸻

📁 ディレクトリ構成（例）

project/
├── fastapi_app/
│   ├── main.py
│   └── celery_app.py
├── worker_app/
│   ├── tasks.py
│   └── celery_app.py  ← 共通でもOK
├── docker-compose.yml


⸻

🐍 1. fastapi_app/celery_app.py（共通Celery設定）

from celery import Celery

celery_app = Celery(
    "worker",
    broker="redis://redis:6379/0",
    backend="redis://redis:6379/0",
)


⸻

🐍 2. fastapi_app/main.py（FastAPIからタスク実行）

from fastapi import FastAPI
from fastapi.requests import Request
from fastapi.responses import JSONResponse

from celery_app import celery_app

app = FastAPI()

@app.post("/run-task/")
async def run_task(request: Request):
    data = await request.json()
    task = celery_app.send_task("worker_app.tasks.process_job", args=[data])
    return JSONResponse({"task_id": task.id})


⸻

🐍 3. worker_app/tasks.py（Python実行環境：処理本体）

from celery_app import celery_app

@celery_app.task(name="worker_app.tasks.process_job")
def process_job(data):
    print(f"[Worker] 処理中: {data}")
    # 実際の処理をここに記述（例：学習、推論など）
    return f"処理完了: {data}"


⸻

🐳 4. docker-compose.yml（Docker構成）

version: "3.9"
services:
  redis:
    image: redis:7
    ports:
      - "6379:6379"

  fastapi:
    build:
      context: ./fastapi_app
    command: uvicorn main:app --host 0.0.0.0 --port 8000
    ports:
      - "8000:8000"
    depends_on:
      - redis

  worker:
    build:
      context: ./worker_app
    command: celery -A tasks worker --loglevel=info
    depends_on:
      - redis


⸻

📦 Dockerfile（FastAPI & Worker 両方同じでOK）

fastapi_app/Dockerfile & worker_app/Dockerfile：

FROM python:3.10-slim

WORKDIR /app

COPY . /app

RUN pip install --no-cache-dir fastapi uvicorn celery redis

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]

※Worker 側では CMD は使わず、docker-compose.yml で celery -A tasks worker を指定

⸻

✅ 動作確認

curl -X POST http://localhost:8000/run-task/ \
     -H "Content-Type: application/json" \
     -d '{"message": "こんにちは"}'

Worker 側コンテナにて：

[Worker] 処理中: {'message': 'こんにちは'}


⸻

