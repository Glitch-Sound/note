# -*- coding: utf-8 -*-
from __future__ import annotations

import os
import time
import threading
from queue import Empty
from typing import TYPE_CHECKING

import numpy as np
import sounddevice as sd
import soundfile as sf
import multiprocessing as mp

# 型注釈用（「Variable not allowed in type expression」対策）
if TYPE_CHECKING:
    from multiprocessing.synchronize import Event as MpEvent
    from multiprocessing.queues import Queue as MpQueue

FS = 44100          # サンプリング周波数
SEC = 5             # 最大録音長（秒）
CH  = 1             # モノラル

CMD_START = "start"     # payload: {"path": "<wav path>"}
CMD_STOP  = "stop"      # 途中停止（B）
CMD_QUIT  = "quit"      # ワーカー終了

def rec_worker(ctrl_q: 'MpQueue', done_q: 'MpQueue') -> None:
    """
    親から:
      - ("start", {"path": ...})
      - ("stop", None)
      - ("quit", None)
    を受け取り、録音→WAV保存して done_q に {"ok": True, "path": ...} を返す
    """
    while True:
        cmd, payload = ctrl_q.get()
        if cmd == CMD_QUIT:
            break

        if cmd != CMD_START:
            # 無視して待ち直し
            continue

        out_path = payload["path"]
        nmax = FS * SEC

        buf = np.empty((nmax, CH), dtype=np.float32)
        idx = 0                      # 現在まで詰めたサンプル数
        stop_now = threading.Event() # B発生で True

        # コールバック：受け取ったフレームをバッファに詰める
        def callback(indata, frames, time_info, status):
            nonlocal idx
            if status:
                # グリッチ等は必要に応じてログ
                pass
            n = min(frames, nmax - idx)
            if n > 0:
                buf[idx:idx+n, :] = indata[:n, :]
                idx += n
            # 5秒分埋まった or B指示が来たら止める
            if idx >= nmax or stop_now.is_set():
                raise sd.CallbackStop

        # 録音開始
        with sd.InputStream(samplerate=FS, channels=CH, dtype='float32',
                            callback=callback, blocksize=0):
            # 録音中は制御キューをポーリングして stop/quit を拾う
            while True:
                if stop_now.is_set():
                    break
                if idx >= nmax:
                    break
                try:
                    c, _ = ctrl_q.get(timeout=0.05)
                    if c == CMD_STOP:
                        stop_now.set()
                    elif c == CMD_QUIT:
                        stop_now.set()
                        # quit は録れた分だけ保存してからやめる
                except Empty:
                    pass

        # 録れた分（idx サンプル）だけ保存
        os.makedirs(os.path.dirname(out_path), exist_ok=True)
        sf.write(out_path, buf[:idx, :], FS)
        done_q.put({"ok": True, "path": out_path, "samples": idx})

    done_q.put({"ok": True, "bye": True})


def main():
    if os.name == "nt":
        mp.set_start_method("spawn", force=True)

    ctrl_q: 'MpQueue' = mp.Queue()
    done_q: 'MpQueue' = mp.Queue()
    p = mp.Process(target=rec_worker, args=(ctrl_q, done_q))
    p.start()

    try:
        # ===== ここは例：条件A/Bの発生をシミュレート =====
        # 条件A：録音スタート
        t = time.strftime("%Y%m%d_%H%M%S")
        wav_path = f"./debug_sound/{t}.wav"
        ctrl_q.put((CMD_START, {"path": wav_path}))

        # 途中で条件Bが起きる想定：2.1秒後に通知
        time.sleep(2.1)
        ctrl_q.put((CMD_STOP, None))

        # ワーカーからの完了を受け取る
        res = done_q.get()
        print("saved:", res)

    finally:
        ctrl_q.put((CMD_QUIT, None))
        p.join(timeout=3)
        if p.is_alive():
            p.terminate()
            p.join()

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        pass



FS = 44100  # sample rate

def _save_librosa_spectrogram_image(filename: str, data, fs: int = FS):
    import numpy as np, os, librosa, librosa.display, matplotlib.pyplot as plt

    # --- 1) 1Dモノラルに正規化（(N,1) や (N,2) を吸収） ---
    y = np.asarray(data)
    if y.ndim == 2:
        if y.shape[1] == 1:
            y = y[:, 0]
        else:
            # (channels, n) を期待するので転置して to_mono
            y = librosa.to_mono(y.T)
    y = y.astype(np.float32, copy=False)

    # 空や極端に短い場合はスキップ（お好みで空画像保存でもOK）
    if y.size < 2:
        return  # 何もせず戻る

    # --- 2) 信号長に合わせて n_fft / hop を調整 ---
    def pow2_floor(n: int) -> int:
        import math
        return 1 << max(6, int(math.floor(math.log2(max(1, n)))))  # 最小64

    n_fft_default = 2048
    if y.size >= n_fft_default:
        n_fft = n_fft_default
    else:
        n_fft = pow2_floor(y.size)         # yの長さ以下で最大の2の冪
        # 2048固定で描きたいなら↓代わりにゼロ埋め
        # y = librosa.util.fix_length(y, size=n_fft_default); n_fft = n_fft_default

    hop_length = max(1, n_fft // 4)

    # --- 3) STFT → dB へ ---
    D = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)
    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)

    # --- 4) 描画（使用した hop を渡すと x軸が正しくなる） ---
    plt.figure(figsize=(10, 4))
    librosa.display.specshow(S_db, sr=fs, hop_length=hop_length,
                             x_axis="time", y_axis="log", cmap="magma")
    plt.colorbar(format="%+2.0f dB")
    plt.title(f"Spectrogram (librosa) n_fft={n_fft}, hop={hop_length}")
    plt.tight_layout()
    plt.savefig(os.path.join(PATH_DEST, filename))
    plt.close()




import numpy as np
import noisereduce as nr

def reduce_noise(data, noise_profile_sec, fs=FS):
    # 1) dataを必ず1D(float32)にする
    y = np.asarray(data, dtype=np.float32)
    if y.ndim == 2:
        # 典型: (n_frames, frame_len) → 直列化して1Dに
        if y.shape[0] > 2 and y.shape[1] > 2:
            y = y.reshape(-1)
        # 典型: (T, C) / (C, T) → モノラル化
        elif y.shape[0] in (1, 2):
            y = y.mean(axis=0)          # (C, T)とみなす
        elif y.shape[1] in (1, 2):
            y = y.mean(axis=1)          # (T, C)とみなす
        else:
            y = y.reshape(-1)
    elif y.ndim > 2:
        y = y.reshape(-1)

    # 2) ノイズプロファイルとターゲットを切り出し
    prof_samples = int(noise_profile_sec * fs)
    assert prof_samples < y.size, "noise_profile_sec が長すぎます"
    noise_profile = y[:prof_samples]
    target       = y[prof_samples:]

    # 3) ノイズリダクション
    reduced = nr.reduce_noise(y=target, y_noise=noise_profile, sr=fs)
    return reduced


